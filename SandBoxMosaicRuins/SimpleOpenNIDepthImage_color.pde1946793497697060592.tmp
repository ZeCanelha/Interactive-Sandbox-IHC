/* --------------------------------------------------------------------------
 * SimpleOpenNI DepthImage Test
 * --------------------------------------------------------------------------
 * Processing Wrapper for the OpenNI/Kinect 2 library
 * http://code.google.com/p/simple-openni
 * --------------------------------------------------------------------------
 * prog:  Max Rheiner / Interaction Design / Zhdk / http://iad.zhdk.ch/
 * date:  12/12/2012 (m/d/y)
 * ----------------------------------------------------------------------------
 */

import SimpleOpenNI.*;


SimpleOpenNI  context;


/**
 * This is a simple example of how to use the Keystone library.
 *
 * To use this example in the real world, you need a projector
 * and a surface you want to project your Processing sketch onto.
 *
 * Simply drag the corners of the CornerPinSurface so that they
 * match the physical surface's corners. The result will be an
 * undistorted projection, regardless of projector position or 
 * orientation.
 *
 * You can also create more than one Surface object, and project
 * onto multiple flat surfaces using a single projector.
 *
 * This extra flexbility can comes at the sacrifice of more or 
 * less pixel resolution, depending on your projector and how
 * many surfaces you want to map. 
 */

import deadpixel.keystone.*;

Keystone ks;
CornerPinSurface surface;

PGraphics offscreen;

int cropLeft = 10; 
int cropRight = 10;
int cropTop = 10;
int cropBottom = 90;
boolean cropping = true;


void setup() {
  //fullScreen(P3D, 2);
  size(640, 480, P3D);
  context = new SimpleOpenNI(this);
  if (context.isInit() == false)
  {
    println("Can't init SimpleOpenNI, maybe the camera is not connected!"); 
    exit();
    return;
  }

  // mirror is by default enabled
  // context.setMirror(true);

  // enable depthMap generation 
  context.enableDepth();


  ks = new Keystone(this);
  surface = ks.createCornerPinSurface(width, height, 20);

  // We need an offscreen buffer to draw the surface we
  // want projected
  // note that we're matching the resolution of the
  // CornerPinSurface.
  // (The offscreen buffer can be P2D or P3D)
  offscreen = createGraphics(width, height, P3D);
}

void draw() {
  context.update();
  PImage depthImage = context.depthImage().get(cropLeft, cropTop, width-cropRight-cropLeft, height-cropBottom-cropTop);
 // depthImage.resize(width, height);
  // Convert the mouse coordinate into surface coordinates
  // this will allow you to use mouse events inside the 
  // surface from your screen. 
  PVector surfaceMouse = surface.getTransformedMouse();

  // Draw the scene, offscreen
  offscreen.beginDraw();



  //background(200, 0, 0);

  // draw depthImageMap
  println(width);
  offscreen.image(depthImage, 0, 0, width, height);
  depthImage.loadPixels();
  float mX = map(mouseX, 0, width-1, 0, depthImage.width-1);
  float mY = map(mouseY, 0, height-1, 0, depthImage.height-1);
  println(mX, mY, red(depthImage.pixels[(int)(mY*640+mX)]));
  offscreen.fill(depthImage.pixels[(int)(mY*640+mX)]);
  //offscreen.fill(0, 255, 0);
  offscreen.ellipse(surfaceMouse.x, surfaceMouse.y, 75, 75);
  offscreen.endDraw();

  // most likely, you'll want a black background to minimize
  // bleeding around your projection area
  //background(0);

  if (cropping) {
    stroke(#ff0000);
    line(0, cropTop, width, cropTop);
    line(0, height-cropBottom, width, height-cropBottom);
    line(cropLeft, 0, cropLeft, height);
    line(width-cropRight, 0, width-cropRight, height);
  } 

  // render the scene, transformed using the corner pin surface
  surface.render(offscreen);

  //println(context.depthImage().width);
}

void mouseMoved() {
}
void keyPressed() {
  switch(key) {
  case 'c':
    // enter/leave calibration mode, where surfaces can be warped 
    // and moved
    ks.toggleCalibration();

    break;

  case 'l':
    // loads the saved layout
    ks.load();
    break;

  case 's':
    // saves the layout
    ks.save();
    break;
  }
}